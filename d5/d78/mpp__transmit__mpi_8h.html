<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>CAM6: libraries/FMS/src/mpp/include/mpp_transmit_mpi.h File Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">CAM6
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../dir_bc0718b08fb2015b8e59c47b2805f60c.html">libraries</a></li><li class="navelem"><a class="el" href="../../dir_5d281a422b153bcd488cddfa3e0fb2b9.html">FMS</a></li><li class="navelem"><a class="el" href="../../dir_02d9f1d8f99d6bf390e432522f9a3f08.html">src</a></li><li class="navelem"><a class="el" href="../../dir_540a1243d24e8cc7d46cb1e3576c8aff.html">mpp</a></li><li class="navelem"><a class="el" href="../../dir_9ff9bc93fcec0b2e298abd01c2856036.html">include</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">mpp_transmit_mpi.h File Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &lt;<a class="el" href="../../d4/d6e/mpp__transmit_8inc.html">mpp_transmit.inc</a>&gt;</code><br />
</div><div class="textblock"><div class="dynheader">
Include dependency graph for mpp_transmit_mpi.h:</div>
<div class="dyncontent">
<div class="center"><img src="https://drive.google.com/uc?id=1kxYLNCBnCEXoYdiHb6fWUS6V1a7d0IBI" border="0" usemap="#alibraries_2_f_m_s_2src_2mpp_2include_2mpp__transmit__mpi_8h" alt=""/></div>
<map name="alibraries_2_f_m_s_2src_2mpp_2include_2mpp__transmit__mpi_8h" id="alibraries_2_f_m_s_2src_2mpp_2include_2mpp__transmit__mpi_8h">
<area shape="rect" title=" " alt="" coords="5,5,195,45"/>
<area shape="rect" href="../../d4/d6e/mpp__transmit_8inc.html" title=" " alt="" coords="39,93,161,119"/>
</map>
</div>
</div>
<p><a href="../../d5/d78/mpp__transmit__mpi_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ab226ac42321bfc92d56940fe308e0c0c"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab226ac42321bfc92d56940fe308e0c0c">!if</a> (debug) write(stderr()</td></tr>
<tr class="separator:ab226ac42321bfc92d56940fe308e0c0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c08eee88fabd386f15a041a6307e9af"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0c08eee88fabd386f15a041a6307e9af">MPI_WAIT</a> (<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>), stat, <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a>) ! <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)) then call MPI_ISEND(put_data</td></tr>
<tr class="separator:a0c08eee88fabd386f15a041a6307e9af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05475c12b996ec0ca277ae88a4ec6efd"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, get_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your get_data array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) ::get_data(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> (<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">i</a>)</td></tr>
<tr class="separator:a05475c12b996ec0ca277ae88a4ec6efd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9941737bce5f0a2158f051221536c295"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a9941737bce5f0a2158f051221536c295">mpp_error</a> (FATAL, 'MPP_TRANSMIT:you cannot transmit to ANY_PE using MPI.') <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.NE.NULL_PE) then !no other valid cases except NULL_PE call mpp_error(FATAL</td></tr>
<tr class="separator:a9941737bce5f0a2158f051221536c295"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a296a1ce4aa242f449a6389a5d514ca87"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG if(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! if(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a> (from_pe.GE.0 .AND. from_pe.LT.npes) then !receive from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> if(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick) if(block_comm) then call MPI_RECV(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a></td></tr>
<tr class="separator:a296a1ce4aa242f449a6389a5d514ca87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9daceacec3963433b91fba6914afc420"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a9daceacec3963433b91fba6914afc420">MPI_GET_COUNT</a> (stat, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a6f16eed4a60c80b7c28954161f54a535">MPI_TYPE_</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">rsize</a>, <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a>) <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">rsize</a> .NE. <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>) then print *</td></tr>
<tr class="separator:a9daceacec3963433b91fba6914afc420"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a8a9d8555f2d7044064deebcfa53bd7"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a2a8a9d8555f2d7044064deebcfa53bd7">MPI_IRECV</a> (<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a6f16eed4a60c80b7c28954161f54a535">MPI_TYPE_</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afa1a81ca499f6e8eb317c510148115da">mpp_comm_private</a>, &amp;request_recv(cur_recv_request), <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a>) size_recv(cur_recv_request)</td></tr>
<tr class="separator:a2a8a9d8555f2d7044064deebcfa53bd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47e1a1106a81ee3f58a391502431a2a1"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a47e1a1106a81ee3f58a391502431a2a1">MPP_BROADCAST_</a> (data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, pelist) !this call was originally bundled in with mpp_transmit</td></tr>
<tr class="separator:a47e1a1106a81ee3f58a391502431a2a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac961d0cdc90f9d1934fac24b6b4eb96d"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG if(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! if(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout)&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac961d0cdc90f9d1934fac24b6b4eb96d">if</a> (peset(n)%count.EQ.1) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> if(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit</td></tr>
<tr class="separator:ac961d0cdc90f9d1934fac24b6b4eb96d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cf66d601e1b30bf8cdd4f4e2c2ca30c"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG if(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! if(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0cf66d601e1b30bf8cdd4f4e2c2ca30c">if</a> (.NOT.ANY(from_pe.EQ.peset(current_peset_num)%list)) &amp;call mpp_error(FATAL</td></tr>
<tr class="separator:a0cf66d601e1b30bf8cdd4f4e2c2ca30c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a79954fc7535bb7a0f37b97c3dbb8b290"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a79954fc7535bb7a0f37b97c3dbb8b290">not</a></td></tr>
<tr class="separator:a79954fc7535bb7a0f37b97c3dbb8b290"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f38fb53f2342c9d71f2819c830785fa"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7f38fb53f2342c9d71f2819c830785fa">sending</a></td></tr>
<tr class="separator:a7f38fb53f2342c9d71f2819c830785fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a769f5d76f508ce809086067fc6bd48e8"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', pe, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from pe-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a769f5d76f508ce809086067fc6bd48e8">pe</a></td></tr>
<tr class="separator:a769f5d76f508ce809086067fc6bd48e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8fb8fc57dac3866d84219f843a82d34"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) ::put_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, put_len, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, put_len, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a></td></tr>
<tr class="separator:ac8fb8fc57dac3866d84219f843a82d34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f16eed4a60c80b7c28954161f54a535"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a6f16eed4a60c80b7c28954161f54a535">MPI_TYPE_</a></td></tr>
<tr class="separator:a6f16eed4a60c80b7c28954161f54a535"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a915417751e9b7305d1d46bddf319869b"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, to_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to to_pe '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, to_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(to_pe).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; to_pe in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for to_pe !call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a915417751e9b7305d1d46bddf319869b">to_pe</a></td></tr>
<tr class="separator:a915417751e9b7305d1d46bddf319869b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24071420f120c6f09f4ee8e8dba3936a"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> ::comm_tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> comm_tag=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) comm_tag=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a></td></tr>
<tr class="separator:a24071420f120c6f09f4ee8e8dba3936a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa1a81ca499f6e8eb317c510148115da"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afa1a81ca499f6e8eb317c510148115da">mpp_comm_private</a></td></tr>
<tr class="separator:afa1a81ca499f6e8eb317c510148115da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b23f6693c15fe5c026153ce0a5556d0"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, send_request logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a></td></tr>
<tr class="separator:a4b23f6693c15fe5c026153ce0a5556d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61b2b58324acdbd0a6c4a78f8a2615e0"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a61b2b58324acdbd0a6c4a78f8a2615e0">cur_send_request</a></td></tr>
<tr class="separator:a61b2b58324acdbd0a6c4a78f8a2615e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e286dea70ebddf537d768b308ca9bac"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' MPP_TRANSMIT begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a></td></tr>
<tr class="separator:a0e286dea70ebddf537d768b308ca9bac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d4d76e224e40d5ed5a38b97e69d3a4d"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, get_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, get_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, get_len=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, get_len <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> get_len so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a></td></tr>
<tr class="separator:a3d4d76e224e40d5ed5a38b97e69d3a4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c71435ff9589d7be2ebdc3d60b74e17"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, from_pe, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from from_pe '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, from_pe <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, from_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, from_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a2c71435ff9589d7be2ebdc3d60b74e17">from_pe</a></td></tr>
<tr class="separator:a2c71435ff9589d7be2ebdc3d60b74e17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad02142075b60923d9fb59362004c89d8"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad02142075b60923d9fb59362004c89d8">stat</a></td></tr>
<tr class="separator:ad02142075b60923d9fb59362004c89d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad99422e397ccf32ee29ad905bc4f8c5e"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> ::rsize <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">rsize</a></td></tr>
<tr class="separator:ad99422e397ccf32ee29ad905bc4f8c5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e71b234432027f9df973da7e3a60b23"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(tick) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', tick, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a></td></tr>
<tr class="separator:a7e71b234432027f9df973da7e3a60b23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8be2e103ee140a2cfd34cd8442ad011"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' PE=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *PE waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote PE is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8be2e103ee140a2cfd34cd8442ad011">PE</a> ='</td></tr>
<tr class="separator:ac8be2e103ee140a2cfd34cd8442ad011"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80d285b74f243e915865ca7e8b5b99c2"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> end <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a80d285b74f243e915865ca7e8b5b99c2">end</a></td></tr>
<tr class="separator:a80d285b74f243e915865ca7e8b5b99c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6d001b8d48cbacf423179c46cffa5a3"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a></td></tr>
<tr class="separator:ab6d001b8d48cbacf423179c46cffa5a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad17f7aca28c97063f01644547e7c1951"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> MPP_TYPE_, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a></td></tr>
<tr class="separator:ad17f7aca28c97063f01644547e7c1951"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9e078ecd82237cedcfa04adf426f745"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout)&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aa9e078ecd82237cedcfa04adf426f745">a</a></td></tr>
<tr class="separator:aa9e078ecd82237cedcfa04adf426f745"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee7a3a5cefee9530beeb7d8d048678f0"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, i18, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout)&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a></td></tr>
<tr class="separator:aee7a3a5cefee9530beeb7d8d048678f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20daaf1e3eb96113e99946f6839d4ed0"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, i6, a, 2i6, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout)&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a></td></tr>
<tr class="separator:a20daaf1e3eb96113e99946f6839d4ed0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71df709a7f4574add895912af26f1ae3"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'T=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a> ='</td></tr>
<tr class="separator:a71df709a7f4574add895912af26f1ae3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a368e49c9ffbb7519f73a8fcccdf89490"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a368e49c9ffbb7519f73a8fcccdf89490">begin</a></td></tr>
<tr class="separator:a368e49c9ffbb7519f73a8fcccdf89490"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88ebfbce0e98427a59baca6a7c82a4bd"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass length, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> ='</td></tr>
<tr class="separator:a88ebfbce0e98427a59baca6a7c82a4bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe40b2e14584c523a2a096237e6f629d"><td class="memItemLeft" align="right" valign="top">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !MPP_BROADCAST !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) MPP_BROADCAST <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a></td></tr>
<tr class="separator:afe40b2e14584c523a2a096237e6f629d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="ab226ac42321bfc92d56940fe308e0c0c" name="ab226ac42321bfc92d56940fe308e0c0c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab226ac42321bfc92d56940fe308e0c0c">&#9670;&#160;</a></span>!if()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE: <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue !<a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> </td>
          <td>(</td>
          <td class="paramtype">debug&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a05475c12b996ec0ca277ae88a4ec6efd" name="a05475c12b996ec0ca277ae88a4ec6efd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05475c12b996ec0ca277ae88a4ec6efd">&#9670;&#160;</a></span>get_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, get_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your get_data array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) ::get_data(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> get_data </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">i</a>&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0cf66d601e1b30bf8cdd4f4e2c2ca30c" name="a0cf66d601e1b30bf8cdd4f4e2c2ca30c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0cf66d601e1b30bf8cdd4f4e2c2ca30c">&#9670;&#160;</a></span>if() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG if(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! if(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if if </td>
          <td>(</td>
          <td class="paramtype">.NOT.&#160;</td>
          <td class="paramname"><em>ANY</em>from_pe.EQ.peset(current_peset_num)%list</td><td>)</td>
          <td> &amp;</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a296a1ce4aa242f449a6389a5d514ca87" name="a296a1ce4aa242f449a6389a5d514ca87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a296a1ce4aa242f449a6389a5d514ca87">&#9670;&#160;</a></span>if() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG if(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! if(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete if </td>
          <td>(</td>
          <td class="paramtype">from_pe.GE.0 .AND. from_pe.LT.&#160;</td>
          <td class="paramname"><em>npes</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac961d0cdc90f9d1934fac24b6b4eb96d" name="ac961d0cdc90f9d1934fac24b6b4eb96d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac961d0cdc90f9d1934fac24b6b4eb96d">&#9670;&#160;</a></span>if() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG if(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! if(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> if <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) if </td>
          <td>(</td>
          <td class="paramtype">peset(n)%count.EQ.&#160;</td>
          <td class="paramname"><em>1</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9daceacec3963433b91fba6914afc420" name="a9daceacec3963433b91fba6914afc420"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9daceacec3963433b91fba6914afc420">&#9670;&#160;</a></span>MPI_GET_COUNT()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call MPI_GET_COUNT </td>
          <td>(</td>
          <td class="paramtype">stat&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a6f16eed4a60c80b7c28954161f54a535">MPI_TYPE_</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">rsize</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a>&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2a8a9d8555f2d7044064deebcfa53bd7" name="a2a8a9d8555f2d7044064deebcfa53bd7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a8a9d8555f2d7044064deebcfa53bd7">&#9670;&#160;</a></span>MPI_IRECV()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call MPI_IRECV </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a6f16eed4a60c80b7c28954161f54a535">MPI_TYPE_</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afa1a81ca499f6e8eb317c510148115da">mpp_comm_private</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&amp;&#160;</td>
          <td class="paramname"><em>request_recv</em>cur_recv_request, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a>&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0c08eee88fabd386f15a041a6307e9af" name="a0c08eee88fabd386f15a041a6307e9af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c08eee88fabd386f15a041a6307e9af">&#9670;&#160;</a></span>MPI_WAIT()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call MPI_WAIT </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>)&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">stat&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a>&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a47e1a1106a81ee3f58a391502431a2a1" name="a47e1a1106a81ee3f58a391502431a2a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47e1a1106a81ee3f58a391502431a2a1">&#9670;&#160;</a></span>MPP_BROADCAST_()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine MPP_BROADCAST_ </td>
          <td>(</td>
          <td class="paramtype">data&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pelist&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9941737bce5f0a2158f051221536c295" name="a9941737bce5f0a2158f051221536c295"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9941737bce5f0a2158f051221536c295">&#9670;&#160;</a></span>mpp_error()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call mpp_error </td>
          <td>(</td>
          <td class="paramtype">FATAL&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">'MPP_TRANSMIT:you cannot transmit to ANY_PE using MPI.'&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="https://drive.google.com/uc?id=1ksFIPbLGra1NQdQuHcf7RlXFmbh56rpM" border="0" usemap="#ad5/d78/mpp__transmit__mpi_8h_a9941737bce5f0a2158f051221536c295_icgraph" alt=""/></div>
<map name="ad5/d78/mpp__transmit__mpi_8h_a9941737bce5f0a2158f051221536c295_icgraph" id="ad5/d78/mpp__transmit__mpi_8h_a9941737bce5f0a2158f051221536c295_icgraph">
<area shape="rect" title=" " alt="" coords="725,1376,805,1401"/>
<area shape="rect" href="../../d8/d3a/fv__nudge_8_f90.html#ae934e0b7b518be107f4b7a8982e3f9e7" title=" " alt="" coords="504,5,632,31"/>
<area shape="rect" href="../../d3/da6/namespaceamip__interp__mod.html#a30396597472a9855fe97d78949fc9848" title=" " alt="" coords="489,55,647,95"/>
<area shape="rect" href="../../db/d77/interfaceamip__interp__mod_1_1assignment_07_0a_08.html#a3db3a0eac692c2faca18a6e1610fe337" title=" " alt="" coords="470,119,666,159"/>
<area shape="rect" href="../../df/dbe/namespacefield__manager__mod.html#a8a2e295bd455ae452c73eb4a6ba85e2c" title=" " alt="" coords="497,247,639,287"/>
<area shape="rect" href="../../df/dbe/namespacefield__manager__mod.html#a0b1ee36793ccd1b64f967964585b57d1" title=" " alt="" coords="497,311,639,351"/>
<area shape="rect" href="../../df/dbe/namespacefield__manager__mod.html#a8c0e638a294dd0a396f9e3aa68d10e97" title=" " alt="" coords="497,183,639,223"/>
<area shape="rect" href="../../db/df6/namespacefv__diagnostics__mod.html#a346887b76d170367da1b3a9b7191fa6c" title=" " alt="" coords="499,554,637,594"/>
<area shape="rect" href="../../dc/d73/namespacetime__interp__external__mod.html#ab2aad20000c5aef5485342634627676e" title=" " alt="" coords="469,642,667,682"/>
<area shape="rect" href="../../dc/d73/namespacetime__interp__external__mod.html#a71caa655313fee196846f013adbf395c" title=" " alt="" coords="486,731,650,785"/>
<area shape="rect" href="../../dc/d73/namespacetime__interp__external__mod.html#a75076732769ab52423ae99b4cfcf417d" title=" " alt="" coords="471,885,665,925"/>
<area shape="rect" href="../../dc/d73/namespacetime__interp__external__mod.html#a58284fe61f523a4473024296ade5bcb8" title=" " alt="" coords="201,885,407,925"/>
<area shape="rect" href="../../df/dbe/namespacefield__manager__mod.html#aae3e428c349350a8637a5d9370133bba" title=" " alt="" coords="497,375,639,415"/>
<area shape="rect" href="../../d1/de3/interfaceoda__core__mod_1_1mult__obs__i__mse.html#ad772278881dffb94c4d9777d5f9b47d6" title=" " alt="" coords="227,432,381,487"/>
<area shape="rect" href="../../df/dbe/namespacefield__manager__mod.html#aad02871b54ab77978cf086aaaebcadc4" title=" " alt="" coords="497,1037,639,1077"/>
<area shape="rect" href="../../df/dbe/namespacefield__manager__mod.html#a5efbeebc10113c4b7b7f6476c2b003c9" title=" " alt="" coords="497,439,639,479"/>
<area shape="rect" href="../../d0/d23/namespacefms__io__mod.html#ac4ec4c538233757434c8eedd0fabbc4d" title=" " alt="" coords="491,1125,645,1165"/>
<area shape="rect" href="../../dc/d73/namespacetime__interp__external__mod.html#ac6f2d8a0cfd1d18ede3136f6d71decc0" title=" " alt="" coords="497,1189,639,1229"/>
<area shape="rect" href="../../d9/d5c/interfacehoriz__interp__mod_1_1horiz__interp.html#ac33b0287e440481544eea7ee56a262fe" title=" " alt="" coords="489,1253,647,1308"/>
<area shape="rect" href="../../d5/d2c/namespacehoriz__interp__mod.html#af77c64ca3f1413639ab8cf1b70788712" title=" " alt="" coords="489,1333,647,1373"/>
<area shape="rect" href="../../d8/d29/interfacehoriz__interp__mod_1_1horiz__interp__new.html#a09de23ccded9920879bf49eaf14ba566" title=" " alt="" coords="485,1397,651,1452"/>
<area shape="rect" href="../../d8/d29/interfacehoriz__interp__mod_1_1horiz__interp__new.html#a28e2deb43e2f1ce933ce5162f65405eb" title=" " alt="" coords="485,1476,651,1531"/>
<area shape="rect" href="../../d8/d29/interfacehoriz__interp__mod_1_1horiz__interp__new.html#a2e4a07f6158c9ab9c606bd9cdde2ad97" title=" " alt="" coords="485,1555,651,1609"/>
<area shape="rect" href="../../d8/d29/interfacehoriz__interp__mod_1_1horiz__interp__new.html#a6d68c5d7f45588a14a41a19d20ca276f" title=" " alt="" coords="485,1633,651,1688"/>
<area shape="rect" href="../../dc/d26/namespacehoriz__interp__spherical__mod.html#a5c3cfce7e6516dd9c96a2d31493fe85e" title=" " alt="" coords="474,1713,662,1753"/>
<area shape="rect" href="../../dc/d26/namespacehoriz__interp__spherical__mod.html#a94b66a03c2f1026494809481d4fc5512" title=" " alt="" coords="462,1777,674,1817"/>
<area shape="rect" href="../../dc/d26/namespacehoriz__interp__spherical__mod.html#aa3e73c217022f2a7a6dea833829eb53a" title=" " alt="" coords="459,1841,677,1881"/>
<area shape="rect" href="../../dc/dfa/mpp__read__distributed__ascii_8h.html#a8098cecabfe66637b96100c554a35ec1" title=" " alt="" coords="549,1905,587,1931"/>
<area shape="rect" href="../../d7/dd2/namespacetest__cases__mod.html#afe098f0f0a16a14e3e59312a69374b9e" title=" " alt="" coords="497,1955,639,1995"/>
<area shape="rect" href="../../dc/d73/namespacetime__interp__external__mod.html#a8057518b04011a1abc54f798ad71ce33" title=" " alt="" coords="487,973,649,1013"/>
<area shape="rect" href="../../dc/dcd/namespacefv__grid__utils__mod.html#a9e4bf88962e6eecc388ca075e641d13f" title=" " alt="" coords="502,2043,634,2083"/>
<area shape="rect" href="../../de/d63/mpp__do__global__field_8h.html#ab2f89e7ab8d260359f864182a5f616ff" title=" " alt="" coords="461,2108,675,2133"/>
<area shape="rect" href="../../d1/d2f/mpp__read__2_ddecomp_8h.html#abdc91a1ca36cda718cd0240b84b55c3e" title=" " alt="" coords="533,2157,603,2183"/>
<area shape="rect" href="../../dc/d7d/mpp__type__mpi_8h.html#af712ca44c5a64fc68a23823c904cef41" title=" " alt="" coords="487,2207,649,2232"/>
<area shape="rect" href="../../de/dac/mpp__write__unlimited__axis_8h.html#a16856baadbefbd707efad167dfff02a6" title=" " alt="" coords="540,2256,596,2281"/>
<area shape="rect" href="../../d2/daa/interfacefms__io__mod_1_1parse__mask__table.html#a6510c96687c3d9915b83e2e33c6d4295" title=" " alt="" coords="472,2306,664,2346"/>
<area shape="rect" href="../../dc/d73/namespacetime__interp__external__mod.html#aff9ef57fdcc28ffa97d2539c13ed23cd" title=" " alt="" coords="494,2371,642,2425"/>
<area shape="rect" href="../../dc/dcd/namespacefv__grid__utils__mod.html#adfe8284f08a2363ce2d21dbc79ad3d98" title="The subroutine &#39;spherical_linear_interpolation&#39; interpolates along the great circle connecting points..." alt="" coords="473,2450,663,2490"/>
<area shape="rect" href="../../d6/dd1/interfacetime__interp__external__mod_1_1time__interp__external.html#a811dabb3adb3b15e1f8119cae1813696" title=" " alt="" coords="479,2515,657,2569"/>
<area shape="rect" href="../../d6/dd1/interfacetime__interp__external__mod_1_1time__interp__external.html#affbffeee043a87ef0ab4fe9ba80cbc13" title=" " alt="" coords="479,2593,657,2648"/>
<area shape="rect" href="../../db/d9e/interfacetime__interp__mod_1_1time__interp.html#acb12c191d9d3fb6082fa712e917c467b" title=" " alt="" coords="489,2673,647,2713"/>
<area shape="rect" href="../../d6/dc1/field__manager_8_f90.html#a1f047397cfb966f7a67f834df557d273" title=" " alt="" coords="226,252,382,277"/>
<area shape="rect" href="../../d1/d6e/namespacetracer__manager__mod.html#ad8158f9c1b49acb5c1d4e7e544af3628" title=" " alt="" coords="232,311,376,351"/>
<area shape="rect" href="../../d1/d6e/namespacetracer__manager__mod.html#a518fe1424557bbe2aa3586f42f418e23" title=" " alt="" coords="5,250,149,290"/>
<area shape="rect" href="../../d1/dcd/namespacefv__control__mod.html#a8baf4c284c2c7e91b0eac9244647e903" title="The subroutine &#39;fv_end&#39; terminates FV3, deallocates memory, saves restart files, and stops I/O." alt="" coords="225,561,383,587"/>
<area shape="rect" href="../../d8/deb/namespacehoriz__interp__conserve__mod.html#a35f55bcdce44e601e1b23e6da4d0d2c5" title=" " alt="" coords="197,1125,411,1165"/>
<area shape="rect" href="../../d1/d20/namespacefv__restart__mod.html#a6f6f077869048d667327767ba7d80177" title="The subroutine &#39;fv_restart&#39; initializes the model state, including prognaostic variables and several ..." alt="" coords="240,1945,368,1985"/>
<area shape="rect" href="../../d3/d92/external__ic_8_f90.html#a50b389b209a18f6c37b98e7357ac1388" title=" " alt="" coords="8,2088,147,2113"/>
<area shape="rect" href="../../d0/d8c/fv__treat__da__inc_8_f90.html#a105a681ef0ad6d4edb2889cd61077119" title="&#39;The module &#39;tread_da_increment&#39; contains routines for treating the increments of the prognostic vari..." alt="" coords="222,2009,386,2035"/>
<area shape="rect" href="../../d7/dd2/namespacetest__cases__mod.html#a18ab30d706b11164805c0fa06712936e" title=" " alt="" coords="218,2110,390,2150"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="aa9e078ecd82237cedcfa04adf426f745" name="aa9e078ecd82237cedcfa04adf426f745"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9e078ecd82237cedcfa04adf426f745">&#9670;&#160;</a></span>a</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) a</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a368e49c9ffbb7519f73a8fcccdf89490" name="a368e49c9ffbb7519f73a8fcccdf89490"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a368e49c9ffbb7519f73a8fcccdf89490">&#9670;&#160;</a></span>begin</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> begin</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a24071420f120c6f09f4ee8e8dba3936a" name="a24071420f120c6f09f4ee8e8dba3936a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24071420f120c6f09f4ee8e8dba3936a">&#9670;&#160;</a></span>comm_tag</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> ::comm_tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> comm_tag=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) comm_tag=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete comm_tag</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a61b2b58324acdbd0a6c4a78f8a2615e0" name="a61b2b58324acdbd0a6c4a78f8a2615e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61b2b58324acdbd0a6c4a78f8a2615e0">&#9670;&#160;</a></span>cur_send_request</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> cur_send_request</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">= <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a61b2b58324acdbd0a6c4a78f8a2615e0">cur_send_request</a> + 1</div>
<div class="line">             <span class="keywordflow">if</span>( <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a61b2b58324acdbd0a6c4a78f8a2615e0">cur_send_request</a> &gt; max_request ) call <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a9941737bce5f0a2158f051221536c295">mpp_error</a>(FATAL, &amp;</div>
<div class="line">                <span class="stringliteral">&quot;MPP_TRANSMIT: cur_send_request is greater than max_request, increase mpp_nml request_multiply&quot;</span>)</div>
<div class="line">             call MPI_ISEND( put_data, <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a6f16eed4a60c80b7c28954161f54a535">MPI_TYPE_</a>, <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a915417751e9b7305d1d46bddf319869b">to_pe</a>, <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>, <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#afa1a81ca499f6e8eb317c510148115da">mpp_comm_private</a>, request_send(<a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a61b2b58324acdbd0a6c4a78f8a2615e0">cur_send_request</a>), <a class="code hl_function" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a>)</div>
<div class="line">          endif</div>
<div class="line">          <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a>( debug .and. (current_clock.NE.0) )call increment_current_clock( EVENT_SEND, <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>*MPP_TYPE_BYTELEN_ )</div>
<div class="line">      <a class="code hl_variable" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a>( <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a915417751e9b7305d1d46bddf319869b">to_pe</a>.EQ.ALL_PES )then !this is <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#aa9e078ecd82237cedcfa04adf426f745">a</a> broadcast from <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a2c71435ff9589d7be2ebdc3d60b74e17">from_pe</a></div>
<div class="line">          <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a>( <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a2c71435ff9589d7be2ebdc3d60b74e17">from_pe</a>.LT.0 .OR. <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a2c71435ff9589d7be2ebdc3d60b74e17">from_pe</a>.GE.npes )call mpp_error( FATAL, &#39;<a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a>: broadcasting from invalid <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8be2e103ee140a2cfd34cd8442ad011">PE</a>.&#39; )</div>
<div class="line">          <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a>( <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>.GT.<a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> )call mpp_error( FATAL, &#39;<a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a>: <a class="code hl_variable" href="../../db/d50/mpi_8c.html#a439227feff9d7f55384e8780cfc2eb82">size</a> mismatch between put_data and <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>.&#39; )</div>
<div class="line">          <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a>( <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a769f5d76f508ce809086067fc6bd48e8">pe</a>.EQ.<a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a2c71435ff9589d7be2ebdc3d60b74e17">from_pe</a> )then</div>
<div class="line">              <a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a>( LOC(<a class="code hl_function" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>).NE.LOC(put_data) )then</div>
<div class="line">!dir$ IVDEP</div>
<div class="line">                  do <a class="code hl_variable" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">i</a> = 1</div>
<div class="ttc" id="ampi_8c_html_a439227feff9d7f55384e8780cfc2eb82"><div class="ttname"><a href="../../db/d50/mpi_8c.html#a439227feff9d7f55384e8780cfc2eb82">size</a></div><div class="ttdeci">int size</div><div class="ttdef"><b>Definition:</b> mpi.c:53</div></div>
<div class="ttc" id="ampp__do__redistribute_8h_html_af188112545a45ebe3b3a60cb7cc1b1c0"><div class="ttname"><a href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">i</a></div><div class="ttdeci">l_size !loop over number of fields ke do je do i</div><div class="ttdef"><b>Definition:</b> mpp_do_redistribute.h:71</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a05475c12b996ec0ca277ae88a4ec6efd"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp;'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len get_data(i)</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a0e286dea70ebddf537d768b308ca9bac"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len so only do gets but you cannot have a pure get with MPI call MPP_TRANSMIT</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:109</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a24071420f120c6f09f4ee8e8dba3936a"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call comm_tag</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:81</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a296a1ce4aa242f449a6389a5d514ca87"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a296a1ce4aa242f449a6389a5d514ca87">if</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp;'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put on remote PE is complete if(from_pe.GE.0 .AND. from_pe.LT.npes) then !receive from from_pe if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick) if(block_comm) then call MPI_RECV(get_data</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a2c71435ff9589d7be2ebdc3d60b74e17"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a2c71435ff9589d7be2ebdc3d60b74e17">from_pe</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp;'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put on remote PE is complete from_pe</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:114</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a3d4d76e224e40d5ed5a38b97e69d3a4d"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp;'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put on remote PE is complete get_len</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:114</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a61b2b58324acdbd0a6c4a78f8a2615e0"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a61b2b58324acdbd0a6c4a78f8a2615e0">cur_send_request</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else cur_send_request</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:83</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a6f16eed4a60c80b7c28954161f54a535"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a6f16eed4a60c80b7c28954161f54a535">MPI_TYPE_</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call MPI_TYPE_</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:81</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a769f5d76f508ce809086067fc6bd48e8"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a769f5d76f508ce809086067fc6bd48e8">pe</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp;'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for pe</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:77</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a915417751e9b7305d1d46bddf319869b"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a915417751e9b7305d1d46bddf319869b">to_pe</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call to_pe</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:81</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a9941737bce5f0a2158f051221536c295"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a9941737bce5f0a2158f051221536c295">mpp_error</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len so only do gets but you cannot have a pure get with MPI call mpp_error(FATAL, 'MPP_TRANSMIT:you cannot transmit to ANY_PE using MPI.') else if(to_pe.NE.NULL_PE) then !no other valid cases except NULL_PE call mpp_error(FATAL</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_aa9e078ecd82237cedcfa04adf426f745"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#aa9e078ecd82237cedcfa04adf426f745">a</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp;'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put on remote PE is complete error call increase mpp_nml request_multiply call MPP_TRANSMIT get_len end if return end subroutine MPP_TRANSMIT_ !MPP_BROADCAST !subroutine but that doesn t allow !broadcast to a subset of PEs This version and mpp_transmit will remain !backward compatible intent(inout) a</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:178</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_ac8be2e103ee140a2cfd34cd8442ad011"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8be2e103ee140a2cfd34cd8442ad011">PE</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp;'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call error else get_len so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put on remote PE is complete error call increase mpp_nml request_multiply call PE</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:153</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_ac8fb8fc57dac3866d84219f843a82d34"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call put_len</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:81</div></div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_afa1a81ca499f6e8eb317c510148115da"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#afa1a81ca499f6e8eb317c510148115da">mpp_comm_private</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, to_pe, get_data, get_len, from_pe, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and get_data are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to to_pe 's get_data! your get_data array is got from from_pe 's put_data!i.e we assume that typically(e.g updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(e.g at boundaries)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect not yet implemented)!ideally we would not pass length, but this f77-style call performs better(arrays passed by address, not descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any rank to be passed(avoiding f90 rank conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after integer, intent(in) ::put_len, to_pe, get_len, from_pe MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(out) ::get_data(*) logical, intent(in), optional ::block integer, intent(in), optional ::tag integer, intent(out), optional ::recv_request, send_request logical ::block_comm integer ::i MPP_TYPE_, allocatable, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) integer ::comm_tag integer ::rsize if(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') if(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) return block_comm=.true. if(PRESENT(block)) block_comm=block if(debug) then call SYSTEM_CLOCK(tick) write(stdout_unit,'(a, i18, a, i6, a, 2i6, 2i8)')&amp; 'T=', tick, ' PE=', pe, ' MPP_TRANSMIT begin:to_pe, from_pe, put_len, get_len=', to_pe, from_pe, put_len, get_len end if comm_tag=DEFAULT_TAG if(present(tag)) comm_tag=tag!do put first and then get if(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends if(debug .and.(current_clock.NE.0)) call SYSTEM_CLOCK(start_tick)!z1l:truly non-blocking send.! if(request(to_pe).NE.MPI_REQUEST_NULL) then !only one message from pe-&gt; to_pe in queue *PE waiting for to_pe !call mpp_comm_private</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:81</div></div>
<div class="ttc" id="averif_a_e_8m_html_ac2e9d8f106c9b9c0028392683978b0e5"><div class="ttname"><a href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a></div><div class="ttdeci">grid else</div><div class="ttdef"><b>Definition:</b> verifAE.m:95</div></div>
<div class="ttc" id="averif_bu_8m_html_af95ca3b8baeab4f8d2da1bd43493f8f8"><div class="ttname"><a href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a></div><div class="ttdeci">if tDelyr&lt;=0, error( 'tDel must be positive'), endtDel=tDelyr *SperA;tf=t0+tDel;t=linspace(t0, tf, max(Mt, 1)+1);% internal constants;time grid;max dimensionss0=t0^(-bet) *R0;Rmax=tf^bet *s0;% margin at last timeL=Rmax *1.1;% domain:(x, y) in[0, L] x[0, L]% draw exact initial and final profilesNer=1000;r=linspace(0, L, Ner);% for display;not numericsHexacti=getH(n, alf, bet, H0, R0, t0, t0, r);Hexactf=getH(n, alf, bet, H0, R0, t0, tf, r);figure(1);clf, set(gcf, 'DefaultLineLineWidth', 1.5) plot(r/1000, Hexacti, r/1000, Hexactf);legend([ 't_0=' num2str(t0/SperA) ' a'], [ 't_f=' num2str(tf/SperA) ' a']) hold on, ylabel( 'h in m');grid on, axis([0 L/1000 0 H0 *1.1]);xlabel( 'r in km');title( 'Exact profiles.');figure(2);clf, set(gcf, 'DefaultLineLineWidth', 1.5) plot(r/1000, Hexacti.^(8/3),'--', r/1000, Hexactf.^(8/3));legend([ 't_0=' num2str(t0/SperA) ' a'], [ 't_f=' num2str(tf/SperA) ' a']) hold on, ylabel( 'u in m^{8/3}');grid onset(gca, 'XLim', [0 L/1000]) xlabel( 'r in km');title( 'Exact profiles *of u *.');% start numeric comparisonif Mt==0, return, enddx=L/Nx;dy=dx;[xx, yy]=ndgrid(linspace(0, L, Nx+1), linspace(0, L, Nx+1));% grid in space% ndgrid makes coord sys left-handed;better for computationrr=sqrt(xx.^2+yy.^2);H=getH(n, alf, bet, H0, R0, t0, t0, rr);dt=tDel/Mt;% initial conditionu=H.^(8/3);% initial uin=2:Nx;Rx=(dt/(dx)^2);Ry=(dt/(dy)^2);fx=4 *dx;fy=4 *dy;n2=n+2;nm=(n-1)/2;disp([ 't0=' num2str(t0/SperA) ' years(time since delta mass)']) disp([ 'Rmax=' num2str(Rmax/1000) ' km']) disp([ 'dx=dy=' num2str(dx/1000) ' km']) disp([ 'dt=' num2str(dt/SperA) ' years'])% time-stepping loopwbhandle=waitbar(0, 'COMPUTING NUMERICAL APPROXIMATION. Ctrl-C halts.');ticfor l=1:Mt Hn=zeros(size(H));% H(1,:) is edge with x=0;H(:, 1) is edge with y=0;H(1, 1) is(x, y)=(0, 0) Hn(in, in)=H(in, in) - divQf(in, in);Hn(1, in)=H(1, in) - divQf(1, in);Hn(in, 1)=H(in, 1) - divQf(in, 1);Hn(1, 1)=H(1, 1) - divQf(1, 1);H=max(0, Hn);% apply boundary condition un=zeros(size(u));un(in, in)=u(in, in).^(3/8) - divuQf(in, in);un(1, in)=u(1, in).^(3/8) - divuQf(1, in);un(in, 1)=u(in, 1).^(3/8) - divuQf(in, 1);un(1, 1)=u(1, 1).^(3/8) - divuQf(1, 1);un=max(0, un);% apply boundary condition u=un.^(8/3);% stability diagnostic(uses only interior points;may miss real max by a bit) if l==1 disp([ 'init stability=' num2str(stabindex(in, in))... '(=max(D) *dt/dx^2)']), end if l==Mt disp([ 'final stability=' num2str(stabindex(in, in))... '(=max(D) *dt/dx^2)']), end % occasional check for disaster;waitbar if rem(l, 30)==0 if max(abs(H(floor(Nx/2),:))) &gt; H0 error(['instability(blowup) failure at step ' ... int2str(l)])</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a80d285b74f243e915865ca7e8b5b99c2" name="a80d285b74f243e915865ca7e8b5b99c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80d285b74f243e915865ca7e8b5b99c2">&#9670;&#160;</a></span>end</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> end <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> end</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2c71435ff9589d7be2ebdc3d60b74e17" name="a2c71435ff9589d7be2ebdc3d60b74e17"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2c71435ff9589d7be2ebdc3d60b74e17">&#9670;&#160;</a></span>from_pe</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, from_pe, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from from_pe '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, from_pe <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, from_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, from_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> from_pe</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3d4d76e224e40d5ed5a38b97e69d3a4d" name="a3d4d76e224e40d5ed5a38b97e69d3a4d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d4d76e224e40d5ed5a38b97e69d3a4d">&#9670;&#160;</a></span>get_len</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, get_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, get_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, get_len=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, get_len <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> get_len so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> get_len</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=<span class="stringliteral">&quot;, rsize, get_len, mpp_pe(), from_pe</span></div>
<div class="line"><span class="stringliteral">                call mpp_error(FATAL, &quot;</span><a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a>: <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> does <a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a79954fc7535bb7a0f37b97c3dbb8b290">not</a> match <a class="code hl_variable" href="../../db/d50/mpi_8c.html#a439227feff9d7f55384e8780cfc2eb82">size</a> of data received<span class="stringliteral">&quot;)</span></div>
<div class="line"><span class="stringliteral">             endif</span></div>
<div class="line"><span class="stringliteral">          else</span></div>
<div class="line"><span class="stringliteral">!             if( request_recv(from_pe).NE.MPI_REQUEST_NULL )then !only one message from from_pe-&gt;pe in queue </span></div>
<div class="line"><span class="stringliteral">                !              if( debug )write( stderr(),* )&#39;PE waiting for receiving&#39;, pe, from_pe</span></div>
<div class="line"><span class="stringliteral">!                call MPI_WAIT( request_recv(from_pe), stat, error )</span></div>
<div class="line"><span class="stringliteral">!             end if</span></div>
<div class="line"><span class="stringliteral">             if(PRESENT(recv_request)) then</span></div>
<div class="line"><span class="stringliteral">                call MPI_IRECV( get_data, get_len, MPI_TYPE_, from_pe, comm_tag, mpp_comm_private, &amp;</span></div>
<div class="line"><span class="stringliteral">                  recv_request, error )</span></div>
<div class="line"><span class="stringliteral">             else</span></div>
<div class="line"><span class="stringliteral">                cur_recv_request = cur_recv_request + 1</span></div>
<div class="line"><span class="stringliteral">                if( cur_recv_request &gt; max_request ) call mpp_error(FATAL, &amp;</span></div>
<div class="line"><span class="stringliteral">                &quot;</span><a class="code hl_variable" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a>: cur_recv_request is greater than max_request</div>
<div class="ttc" id="ampp__transmit__mpi_8h_html_a79954fc7535bb7a0f37b97c3dbb8b290"><div class="ttname"><a href="../../d5/d78/mpp__transmit__mpi_8h.html#a79954fc7535bb7a0f37b97c3dbb8b290">not</a></div><div class="ttdeci">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If not</div><div class="ttdef"><b>Definition:</b> mpp_transmit_mpi.h:4</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="aee7a3a5cefee9530beeb7d8d048678f0" name="aee7a3a5cefee9530beeb7d8d048678f0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee7a3a5cefee9530beeb7d8d048678f0">&#9670;&#160;</a></span>i18</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, i18, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) i18</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a20daaf1e3eb96113e99946f6839d4ed0" name="a20daaf1e3eb96113e99946f6839d4ed0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20daaf1e3eb96113e99946f6839d4ed0">&#9670;&#160;</a></span>i6</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, i6, a, 2i6, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) i6</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a88ebfbce0e98427a59baca6a7c82a4bd" name="a88ebfbce0e98427a59baca6a7c82a4bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88ebfbce0e98427a59baca6a7c82a4bd">&#9670;&#160;</a></span>length</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass length, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; length &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> length ='</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6f16eed4a60c80b7c28954161f54a535" name="a6f16eed4a60c80b7c28954161f54a535"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f16eed4a60c80b7c28954161f54a535">&#9670;&#160;</a></span>MPI_TYPE_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete MPI_TYPE_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afe40b2e14584c523a2a096237e6f629d" name="afe40b2e14584c523a2a096237e6f629d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe40b2e14584c523a2a096237e6f629d">&#9670;&#160;</a></span>MPP_BROADCAST</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !MPP_BROADCAST !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) MPP_BROADCAST <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> MPP_BROADCAST</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afa1a81ca499f6e8eb317c510148115da" name="afa1a81ca499f6e8eb317c510148115da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afa1a81ca499f6e8eb317c510148115da">&#9670;&#160;</a></span>mpp_comm_private</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete mpp_comm_private</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0e286dea70ebddf537d768b308ca9bac" name="a0e286dea70ebddf537d768b308ca9bac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e286dea70ebddf537d768b308ca9bac">&#9670;&#160;</a></span>MPP_TRANSMIT</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! MPP_TRANSMIT !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' MPP_TRANSMIT begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call MPP_TRANSMIT</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad17f7aca28c97063f01644547e7c1951" name="ad17f7aca28c97063f01644547e7c1951"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad17f7aca28c97063f01644547e7c1951">&#9670;&#160;</a></span>MPP_TYPE_</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous MPP_TYPE_ arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> MPP_TYPE_, intent(in) ::put_data(*) MPP_TYPE_, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> MPP_TYPE_, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible MPP_TYPE_</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a79954fc7535bb7a0f37b97c3dbb8b290" name="a79954fc7535bb7a0f37b97c3dbb8b290"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79954fc7535bb7a0f37b97c3dbb8b290">&#9670;&#160;</a></span>not</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">*********************************************************************** * GNU Lesser General Public License* * This file is part of the GFDL Flexible Modeling System (FMS). !* !* FMS is free software without even the implied warranty of MERCHANTABILITY or* FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License* for more details* * You should have received a copy of the GNU Lesser General Public* License along with FMS If not</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a769f5d76f508ce809086067fc6bd48e8" name="a769f5d76f508ce809086067fc6bd48e8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a769f5d76f508ce809086067fc6bd48e8">&#9670;&#160;</a></span>pe</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', pe, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from pe-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) pe</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac8be2e103ee140a2cfd34cd8442ad011" name="ac8be2e103ee140a2cfd34cd8442ad011"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac8be2e103ee140a2cfd34cd8442ad011">&#9670;&#160;</a></span>PE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each PE performs a put _and_ a get!special PE designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote PE for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' PE=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *PE waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote PE is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) PE ='</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ac8fb8fc57dac3866d84219f843a82d34" name="ac8fb8fc57dac3866d84219f843a82d34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac8fb8fc57dac3866d84219f843a82d34">&#9670;&#160;</a></span>put_len</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, put_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) ::put_len, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, put_len, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, put_len, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> put_len</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad99422e397ccf32ee29ad905bc4f8c5e" name="ad99422e397ccf32ee29ad905bc4f8c5e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad99422e397ccf32ee29ad905bc4f8c5e">&#9670;&#160;</a></span>rsize</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> ::rsize <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call rsize</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4b23f6693c15fe5c026153ce0a5556d0" name="a4b23f6693c15fe5c026153ce0a5556d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4b23f6693c15fe5c026153ce0a5556d0">&#9670;&#160;</a></span>send_request</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, send_request)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, send_request logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call send_request</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7f38fb53f2342c9d71f2819c830785fa" name="a7f38fb53f2342c9d71f2819c830785fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7f38fb53f2342c9d71f2819c830785fa">&#9670;&#160;</a></span>sending</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE: <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue * <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for sending</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad02142075b60923d9fb59362004c89d8" name="ad02142075b60923d9fb59362004c89d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad02142075b60923d9fb59362004c89d8">&#9670;&#160;</a></span>stat</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete stat</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a71df709a7f4574add895912af26f1ae3" name="a71df709a7f4574add895912af26f1ae3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71df709a7f4574add895912af26f1ae3">&#9670;&#160;</a></span>T</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; 'T=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) &amp; T ='</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7e71b234432027f9df973da7e3a60b23" name="a7e71b234432027f9df973da7e3a60b23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7e71b234432027f9df973da7e3a60b23">&#9670;&#160;</a></span>tick</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(tick) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', tick, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version and mpp_transmit <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ab6d001b8d48cbacf423179c46cffa5a3">will</a> remain !backward compatible intent(inout) tick</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a915417751e9b7305d1d46bddf319869b" name="a915417751e9b7305d1d46bddf319869b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a915417751e9b7305d1d46bddf319869b">&#9670;&#160;</a></span>to_pe</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, to_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to to_pe '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, to_pe, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp; '<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(to_pe).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; to_pe in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for to_pe !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> to_pe</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab6d001b8d48cbacf423179c46cffa5a3" name="ab6d001b8d48cbacf423179c46cffa5a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6d001b8d48cbacf423179c46cffa5a3">&#9670;&#160;</a></span>will</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">************************************************************************GNU Lesser General Public License **This file is part of the GFDL Flexible Modeling System(FMS). ! *! *FMS is free software without even the implied warranty of MERCHANTABILITY or *FITNESS FOR A PARTICULAR PURPOSE See the GNU General Public License *for more details **You should have received a copy of the GNU Lesser General Public *License along with FMS If see&lt; http:! ***********************************************************************!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !! <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> !! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! subroutine MPP_TRANSMIT_(put_data, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, block, tag, recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a>)!a message-passing routine intended to be reminiscent equally of both MPI and SHMEM!put_data and <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> are contiguous <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a> arrays!at each call, your put_data array is put to <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> get_data! your <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">get_data</a> array is got from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> '<a class="el" href="../../df/d2e/verif_a_e_8m.html#afbe9f62a5b71779115b4c4010fd8a89c">s</a> put_data!i.e we assume <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> typically(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> updating halo regions) each <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> performs a put _and_ a get!special <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> designations:! NULL_PE:to disable a put or a get(<a class="el" href="../../df/d2e/verif_a_e_8m.html#ae08fdc96f0c4d4d3041ab1291edfe243">e.g</a> at <a class="el" href="../../da/d90/crmx__boundaries_8_f90.html#adfe433a5357a5f13af1acc21d75f9a27">boundaries</a>)! ANY_PE:if remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> for the put or get is to be unspecific! ALL_PES:broadcast and collect operations(collect <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> yet implemented)!ideally we would <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> pass <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a>, but this f77-style call performs better(arrays passed by address, <a class="el" href="../../d3/d3d/drifters__compute__k_8h.html#aaf68b4e8e89dfb379b579e345c00dbd0">not</a> descriptor)!further, this permits&lt; <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a88ebfbce0e98427a59baca6a7c82a4bd">length</a> &gt; contiguous words from an array of any <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> to be passed(avoiding f90 <a class="el" href="../../d2/de2/cart_8c.html#a04b70f13089815cf7796169bd144f8ee">rank</a> conformance check)!caller is responsible for completion checks(mpp_sync_self) before and after <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">::put_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(in) ::put_data(*) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a05475c12b996ec0ca277ae88a4ec6efd">::get_data</a>(*) logical, intent(in), optional ::block <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(in), optional ::tag <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a>, intent(<a class="el" href="../../dd/d81/trilinos_linear_solver_8cpp.html#accde5065416d529b6bdaf7a813644529">out</a>), optional ::recv_request, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a4b23f6693c15fe5c026153ce0a5556d0">send_request</a> logical ::block_comm <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#af188112545a45ebe3b3a60cb7cc1b1c0">::i</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad17f7aca28c97063f01644547e7c1951">MPP_TYPE_</a>, <a class="el" href="../../de/dac/mpp__write__unlimited__axis_8h.html#ac353729cf971070612d112992761dc0e">allocatable</a>, save ::local_data(:) !local copy used by non-parallel code(no SHMEM or MPI) <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">::comm_tag</a> <a class="el" href="../../d9/d4a/mpp__update__nest__domains_8h.html#a2f1a7b191d819194cc881180b9fa006b">integer</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ad99422e397ccf32ee29ad905bc4f8c5e">::rsize</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(.NOT.module_is_initialized) call mpp_error(FATAL, 'MPP_TRANSMIT:You must first call mpp_init.') <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.EQ.NULL_PE .AND. from_pe.EQ.NULL_PE) <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> block_comm=.true. <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(PRESENT(block)) block_comm=block <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug) then call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>) write(stdout_unit,'(a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#aee7a3a5cefee9530beeb7d8d048678f0">i18</a>, a, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, a, 2<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a20daaf1e3eb96113e99946f6839d4ed0">i6</a>, 2i8)')&amp;'<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a71df709a7f4574add895912af26f1ae3">T</a>=', <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a7e71b234432027f9df973da7e3a60b23">tick</a>, ' <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>, ' <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> begin:to_pe, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a>=', <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>, <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#ae79b98a432865ef0e16924707dc683d9">from_pe</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#ac8fb8fc57dac3866d84219f843a82d34">put_len</a>, <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=DEFAULT_TAG <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(present(tag)) <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a24071420f120c6f09f4ee8e8dba3936a">comm_tag</a>=tag!do put first and then get <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(to_pe.GE.0 .AND. to_pe.LT.npes) then!use non-blocking sends <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(debug .and.(current_clock.NE.0)) call <a class="el" href="../../df/d2f/system__clock_8h.html#a95982eccb57c2ae35f8ba3d8f0b05653">SYSTEM_CLOCK</a>(start_tick)!z1l:truly non-blocking send.! <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a>(<a class="el" href="../../d6/dcb/req_8c.html#a239d9df0faec785c1772c25b05a700ce">request</a>(<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a>).<a class="el" href="../../d1/dd8/mpi_8h.html#a4e555d16d257fe93bc766b4166ed9e2f">NE.MPI_REQUEST_NULL</a>) then !only one message from <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a3bdd9177fef31023437b720c7807e308">pe</a>-&gt; <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> in queue *<a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> waiting for <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#aed4e4a8e44c1dba7f1a040a000b41657">to_pe</a> !call <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> <a class="el" href="../../df/d2e/verif_a_e_8m.html#ac2e9d8f106c9b9c0028392683978b0e5">else</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> so only do gets but you cannot have a pure get with MPI call a get means do a wait to ensure put <a class="el" href="../../df/d2e/verif_a_e_8m.html#a88f96a74aac2484b2b14747bb3d48a4c">on</a> remote <a class="el" href="../../d2/d1c/mpp__do__redistribute_8h.html#a2e47b035c16c4dd776c74a6f8cc44337">PE</a> is complete <a class="el" href="../../dd/dba/verif_bu_8m.html#af95ca3b8baeab4f8d2da1bd43493f8f8">error</a> call increase mpp_nml request_multiply call <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a0e286dea70ebddf537d768b308ca9bac">MPP_TRANSMIT</a> <a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#a3d4d76e224e40d5ed5a38b97e69d3a4d">get_len</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> <a class="el" href="../../db/d50/mpi_8c.html#a163eccda569402d936363f51d62cfba0">if</a> <a class="el" href="../../da/dae/verif_d_8m.html#ad88990eaa4ee2ac6919ddc68ea9617ad">return</a> <a class="el" href="../../dd/dba/verif_bu_8m.html#af5dc6e45ec0e66069f2846df5acf1026">end</a> subroutine MPP_TRANSMIT_ !<a class="el" href="../../d5/d78/mpp__transmit__mpi_8h.html#afe40b2e14584c523a2a096237e6f629d">MPP_BROADCAST</a> !subroutine but <a class="el" href="../../db/d16/debug_8h.html#a4fd82c6e74959ebd9393813b2ded4c7b">that</a> doesn <a class="el" href="../../d1/d41/carma__globaer_8h.html#a1f0cf49f22a9b271d1d9e6e14609faed">t</a> allow !broadcast to a subset of PEs This version will</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6
</small></address>
</body>
</html>
